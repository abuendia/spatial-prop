{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194d0529",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import squidpy as sq\n",
    "import anndata as ad\n",
    "from scipy.stats import pearsonr, spearmanr, ttest_ind\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "from matplotlib.collections import PatchCollection\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "sns.set_style(\"ticks\")\n",
    "from sklearn.neighbors import BallTree\n",
    "from scipy.stats import mannwhitneyu, ttest_ind\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from decimal import Decimal\n",
    "import copy\n",
    "\n",
    "import random\n",
    "\n",
    "os.chdir(\"/oak/stanford/groups/jamesz/abuen/spatial-sc/repos/spatial-gnn/scripts\")\n",
    "from aging_gnn_model import *\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils import k_hop_subgraph, one_hot, to_networkx\n",
    "from torch_geometric.utils.convert import from_scipy_sparse_matrix\n",
    "from torch.nn import Linear, Sequential, BatchNorm1d, ReLU, ModuleList\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GINConv, SAGEConv, global_mean_pool, global_add_pool, global_max_pool\n",
    "from torch.nn.modules.loss import _Loss\n",
    "from torch.distributions import MultivariateNormal as MVN\n",
    "\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cc289d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "celltypes_to_index = {\n",
    "                        'B cells': 0,\n",
    "                        'Epithelial cells': 1,\n",
    "                        'Fibroblasts/stromal cells': 2,\n",
    "                        'Myeloid cells': 3,\n",
    "                        'Neutrophils': 4,\n",
    "                        'T cells': 5,\n",
    "                                    },"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756edc7d",
   "metadata": {},
   "source": [
    "## Predict gene expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7039f1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json \n",
    "\n",
    "def load_dataset_config():\n",
    "    \"\"\"Load dataset configurations from JSON file.\"\"\"\n",
    "    config_path = \"/oak/stanford/groups/jamesz/abuen/spatial-sc/repos/spatial-gnn/config/datasets.json\"\n",
    "    try:\n",
    "        with open(config_path, 'r') as f:\n",
    "            return json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"Dataset configuration file not found at {config_path}\")\n",
    "    except json.JSONDecodeError:\n",
    "        raise ValueError(f\"Invalid JSON format in dataset configuration file at {config_path}\")\n",
    "\n",
    "DATASET_CONFIGS = load_dataset_config()\n",
    "dataset_config = DATASET_CONFIGS[\"allen\"]\n",
    "\n",
    "train_ids = dataset_config[\"train_ids\"]\n",
    "test_ids = dataset_config[\"test_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aeb111a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get params\n",
    "k_hop = 2\n",
    "augment_hop = 2\n",
    "center_celltypes = [\"Neutrophils\", \"Epithelial cells\"]\n",
    "node_feature = \"expression\"\n",
    "loss = \"weightedl1\"\n",
    "learning_rate = 0.0001\n",
    "use_model = \"model\"\n",
    "#use_model = \"best_model\"\n",
    "inject_feature = \"center_celltype\"\n",
    "inject=False\n",
    "\n",
    "#--------------------------------------------------------------\n",
    "\n",
    "if inject is False:\n",
    "    inject_feature = None\n",
    "\n",
    "file_path = \"/oak/stanford/groups/jamesz/abuen/spatial-sc/data/raw/CART-TMA1-spatial-filt.h5ad\"\n",
    "\n",
    "# init dataset with settings\n",
    "train_dataset = SpatialAgingCellDataset(dataset=\"cart\", \n",
    "                                        subfolder_name=\"train\",\n",
    "                                        target=\"expression\",\n",
    "                                        k_hop=k_hop,\n",
    "                                        augment_hop=augment_hop,\n",
    "                                        node_feature=node_feature,\n",
    "                                        inject_feature=inject_feature,\n",
    "                                        num_cells_per_ct_id=100,\n",
    "                                        center_celltypes=center_celltypes,\n",
    "                                        sub_id=\"Patient_ID\",\n",
    "                                        use_ids=train_ids,\n",
    "                                        file_path=file_path,\n",
    "                                        gene_list=None)\n",
    "\n",
    "test_dataset = SpatialAgingCellDataset(dataset=\"cart\",\n",
    "                                    subfolder_name=\"test\",\n",
    "                                    target=\"expression\",\n",
    "                                    k_hop=k_hop,\n",
    "                                    augment_hop=augment_hop,\n",
    "                                    node_feature=node_feature,\n",
    "                                    inject_feature=inject_feature,\n",
    "                                    num_cells_per_ct_id=100,\n",
    "                                    center_celltypes=center_celltypes,\n",
    "                                    sub_id=\"Patient_ID\",\n",
    "                                    use_ids=test_ids,\n",
    "                                    file_path=file_path,\n",
    "                                    gene_list=None)\n",
    "\n",
    "# concatenate datasets\n",
    "all_dataset = torch.utils.data.ConcatDataset([train_dataset, test_dataset])\n",
    "\n",
    "# define data loaders\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "all_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# LOAD MODELS\n",
    "model_dirname = loss+f\"_{learning_rate:.0e}\".replace(\"-\",\"n\")\n",
    "save_dir = os.path.join(\"results/gnn\",train_dataset.processed_dir.split(\"/\")[-2],model_dirname)\n",
    "\n",
    "# TRAIN MODEL\n",
    "# init model\n",
    "if inject is True:\n",
    "    model = GNN(hidden_channels=64,\n",
    "                input_dim=int(train_dataset.get(0).x.shape[1]),\n",
    "                output_dim=len(train_dataset.get(0).y), # added for multivariate targets\n",
    "                inject_dim=int(train_dataset.get(0).inject.shape[1]), # added for injecting features into last layer (after pooling)\n",
    "                method=\"GIN\", pool=\"add\", num_layers=k_hop)\n",
    "else:\n",
    "    model = GNN(hidden_channels=64,\n",
    "            input_dim=int(train_dataset.get(0).x.shape[1]),\n",
    "            output_dim=len(train_dataset.get(0).y), # added for multivariate targets\n",
    "            method=\"GIN\", pool=\"add\", num_layers=k_hop)\n",
    "\n",
    "# load model weights\n",
    "model.load_state_dict(torch.load(os.path.join(save_dir, f\"{use_model}.pth\"),\n",
    "                                map_location=torch.device('cpu')))\n",
    "\n",
    "# # ALL MODEL\n",
    "# # init model\n",
    "# all_model = GNN(hidden_channels=16,\n",
    "#             input_dim=int(test_dataset.get(0).x.shape[1]),\n",
    "#             method=\"GIN\", pool=\"add\", num_layers=k_hop)\n",
    "\n",
    "# # load model weights\n",
    "# all_model.load_state_dict(torch.load(os.path.join(save_dir, f\"all_{use_model}.pth\")))\n",
    "\n",
    "from torch_geometric import profile\n",
    "profile.count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918af594",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8027449c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8f487d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# load results\n",
    "with open(os.path.join(save_dir, \"training.pkl\"), 'rb') as handle:\n",
    "    b = pickle.load(handle)\n",
    "    \n",
    "# plot training/validation loss curves\n",
    "\n",
    "best_idx = np.argmin(b['test'])\n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.plot(b['epoch'],b['train'],label='Train',color='0.2',zorder=0)\n",
    "plt.plot(b['epoch'],b['test'],label='Validation',color='green',zorder=1)\n",
    "plt.scatter(b['epoch'][best_idx],b['test'][best_idx],s=50,c='green',marker=\"D\",zorder=2,label=\"Selected model\")\n",
    "plt.ylabel(\"Weighted L1 Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.title(\"Training run on TMA1\")\n",
    "# plt.savefig(f\"plots/gnn/{test_dataset.processed_dir.split('/')[-2]}_losscurves.pdf\",\n",
    "#             bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2df74f",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "514474d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make test predictions\n",
    "\n",
    "model.eval()\n",
    "\n",
    "preds = []\n",
    "actuals = []\n",
    "celltypes = []\n",
    "\n",
    "for data in test_loader:\n",
    "    \n",
    "    if inject is False:\n",
    "        out = model(data.x, data.edge_index, data.batch, None)\n",
    "    else:\n",
    "        out = model(data.x, data.edge_index, data.batch, data.inject)\n",
    "    \n",
    "    preds.append(out)\n",
    "    \n",
    "    if data.y.shape != out.shape:\n",
    "        actuals.append(torch.reshape(data.y.float(), out.shape))\n",
    "    else:\n",
    "        actuals.append(data.y.float())\n",
    "\n",
    "#     if inject is True: # i.e. if cell type is used for center cell // otherwise need to use center_node to get cell type\n",
    "\n",
    "#         cct_mat = data.inject.numpy()\n",
    "\n",
    "#         for i in range(cct_mat.shape[0]):\n",
    "#             ct_idx = np.where(cct_mat[i,:]==1)[0][0]\n",
    "#             celltypes.append(list(celltypes_to_index.keys())[ct_idx])\n",
    "\n",
    "    # get cell type\n",
    "    celltypes = np.concatenate((celltypes,np.concatenate(data.center_celltype)))\n",
    "    \n",
    "preds = np.concatenate([pred.detach().numpy() for pred in preds])\n",
    "actuals = np.concatenate([act.detach().numpy() for act in actuals])\n",
    "\n",
    "celltypes = np.array(celltypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51df5c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENE STATS\n",
    "gene_r = []\n",
    "gene_s = []\n",
    "gene_r2 = []\n",
    "gene_mae = []\n",
    "gene_rmse = []\n",
    "\n",
    "for g in range(preds.shape[1]):\n",
    "    \n",
    "    r, p = pearsonr(preds[:,g], actuals[:,g])\n",
    "    gene_r.append(r)\n",
    "    \n",
    "    s, p = spearmanr(preds[:,g], actuals[:,g])\n",
    "    gene_s.append(s)\n",
    "    \n",
    "    r2 = r2_score(actuals[:,g], preds[:,g])\n",
    "    gene_r2.append(r2)\n",
    "    \n",
    "    gene_mae.append(np.mean(np.abs(preds[:,g]-actuals[:,g])))\n",
    "    gene_rmse.append(np.sqrt(np.mean((preds[:,g]-actuals[:,g])**2)))\n",
    "    \n",
    "\n",
    "# CELL STATS\n",
    "cell_r = []\n",
    "cell_s = []\n",
    "cell_r2 = []\n",
    "cell_mae = []\n",
    "cell_rmse = []\n",
    "\n",
    "for c in range(preds.shape[0]):\n",
    "    \n",
    "    r, p = pearsonr(preds[c,:], actuals[c,:])\n",
    "    cell_r.append(r)\n",
    "    \n",
    "    s, p = spearmanr(preds[c,:], actuals[c,:])\n",
    "    cell_s.append(s)\n",
    "    \n",
    "    r2 = r2_score(actuals[c,:], preds[c,:])\n",
    "    cell_r2.append(r2)\n",
    "    \n",
    "    cell_mae.append(np.mean(np.abs(preds[c,:]-actuals[c,:])))\n",
    "    cell_rmse.append(np.sqrt(np.mean((preds[c,:]-actuals[c,:])**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e981d39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop genes that are missing everywhere\n",
    "preds = preds[:, actuals.max(axis=0)>=0]\n",
    "actuals = actuals[:, actuals.max(axis=0)>=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "145ce9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENE STATS -- NON-NEGATIVE ONLY\n",
    "gene_r = []\n",
    "gene_s = []\n",
    "gene_r2 = []\n",
    "gene_mae = []\n",
    "gene_rmse = []\n",
    "\n",
    "for g in range(preds.shape[1]):\n",
    "    \n",
    "    r, p = pearsonr(preds[actuals[:,g]>=0,g], actuals[actuals[:,g]>=0,g])\n",
    "    gene_r.append(r)\n",
    "    \n",
    "    s, p = spearmanr(preds[actuals[:,g]>=0,g], actuals[actuals[:,g]>=0,g])\n",
    "    gene_s.append(s)\n",
    "    \n",
    "    r2 = r2_score(actuals[actuals[:,g]>=0,g], preds[actuals[:,g]>=0,g])\n",
    "    gene_r2.append(r2)\n",
    "    \n",
    "    gene_mae.append(np.mean(np.abs(preds[actuals[:,g]>=0,g]-actuals[actuals[:,g]>=0,g])))\n",
    "    gene_rmse.append(np.sqrt(np.mean((preds[actuals[:,g]>=0,g]-actuals[actuals[:,g]>=0,g])**2)))\n",
    "    \n",
    "\n",
    "# CELL STATS -- NON-NEGATIVE ONLY\n",
    "cell_r = []\n",
    "cell_s = []\n",
    "cell_r2 = []\n",
    "cell_mae = []\n",
    "cell_rmse = []\n",
    "\n",
    "for c in range(preds.shape[0]):\n",
    "    \n",
    "    r, p = pearsonr(preds[c,actuals[c,:]>=0], actuals[c,actuals[c,:]>=0])\n",
    "    cell_r.append(r)\n",
    "    \n",
    "    s, p = spearmanr(preds[c,actuals[c,:]>=0], actuals[c,actuals[c,:]>=0])\n",
    "    cell_s.append(s)\n",
    "    \n",
    "    r2 = r2_score(actuals[c,actuals[c,:]>=0], preds[c,actuals[c,:]>=0])\n",
    "    cell_r2.append(r2)\n",
    "    \n",
    "    cell_mae.append(np.mean(np.abs(preds[c,actuals[c,:]>=0]-actuals[c,actuals[c,:]>=0])))\n",
    "    cell_rmse.append(np.sqrt(np.mean((preds[c,actuals[c,:]>=0]-actuals[c,actuals[c,:]>=0])**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ddbb39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save gene stats dataframe\n",
    "df_gene = pd.DataFrame(np.vstack((gene_r, gene_s, gene_r2, gene_mae, gene_rmse)).T,\n",
    "                       columns=[\"Pearson\",\"Spearman\",\"R2\",\"MAE\", \"RMSE\"])\n",
    "df_gene.to_csv(os.path.join(save_dir, \"test_evaluation_stats_gene.csv\"), index=False)\n",
    "\n",
    "# save cell stats dataframe\n",
    "df_cell = pd.DataFrame(np.vstack((cell_r, cell_s, cell_r2, cell_mae, cell_rmse)).T,\n",
    "                       columns=[\"Pearson\",\"Spearman\",\"R2\",\"MAE\", \"RMSE\"])\n",
    "df_cell.to_csv(os.path.join(save_dir, \"test_evaluation_stats_cell.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ae5916",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cell.median(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189eb896",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gene.median(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a157d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats broken down by cell type\n",
    "\n",
    "ct_stats_dict = {}\n",
    "\n",
    "for ct in np.unique(celltypes):\n",
    "    \n",
    "    ct_stats_dict[ct] = {}\n",
    "\n",
    "    # GENE STATS\n",
    "    gene_r = []\n",
    "    gene_s = []\n",
    "    gene_r2 = []\n",
    "    gene_mae = []\n",
    "    gene_rmse = []\n",
    "\n",
    "    for g in range(preds.shape[1]):\n",
    "\n",
    "        r, p = pearsonr(preds[celltypes==ct,g], actuals[celltypes==ct,g])\n",
    "        gene_r.append(r)\n",
    "\n",
    "        s, p = spearmanr(preds[celltypes==ct,g], actuals[celltypes==ct,g])\n",
    "        gene_s.append(s)\n",
    "\n",
    "        r2 = r2_score(actuals[celltypes==ct,g], preds[celltypes==ct,g])\n",
    "        gene_r2.append(r2)\n",
    "\n",
    "        gene_mae.append(np.mean(np.abs(preds[celltypes==ct,g]-actuals[celltypes==ct,g])))\n",
    "        gene_rmse.append(np.sqrt(np.mean((preds[celltypes==ct,g]-actuals[celltypes==ct,g])**2)))\n",
    "\n",
    "\n",
    "    # CELL STATS\n",
    "    cell_r = []\n",
    "    cell_s = []\n",
    "    cell_r2 = []\n",
    "    cell_mae = []\n",
    "    cell_rmse = []\n",
    "\n",
    "    for c in np.where(celltypes==ct)[0]:\n",
    "\n",
    "        r, p = pearsonr(preds[c,:], actuals[c,:])\n",
    "        cell_r.append(r)\n",
    "\n",
    "        s, p = spearmanr(preds[c,:], actuals[c,:])\n",
    "        cell_s.append(s)\n",
    "\n",
    "        r2 = r2_score(actuals[c,:], preds[c,:])\n",
    "        cell_r2.append(r2)\n",
    "\n",
    "        cell_mae.append(np.mean(np.abs(preds[c,:]-actuals[c,:])))\n",
    "        cell_rmse.append(np.sqrt(np.mean((preds[c,:]-actuals[c,:])**2)))\n",
    "\n",
    "        pred_ct = celltypes==ct\n",
    "        \n",
    "    # add results to dictionary\n",
    "    ct_stats_dict[ct][\"Gene - Pearson (mean)\"] = np.mean(gene_r)\n",
    "    ct_stats_dict[ct][\"Gene - Pearson (median)\"] = np.median(gene_r)\n",
    "    ct_stats_dict[ct][\"Gene - Spearman (mean)\"] = np.mean(gene_s)\n",
    "    ct_stats_dict[ct][\"Gene - Spearman (median)\"] = np.mean(gene_s)\n",
    "    ct_stats_dict[ct][\"Gene - R2 (mean)\"] = np.mean(gene_r2)\n",
    "    ct_stats_dict[ct][\"Gene - R2 (median)\"] = np.mean(gene_r2)\n",
    "    ct_stats_dict[ct][\"Gene - MAE (mean)\"] = np.mean(gene_mae)\n",
    "    ct_stats_dict[ct][\"Gene - RMSE (mean)\"] = np.mean(gene_rmse)\n",
    "    \n",
    "    ct_stats_dict[ct][\"Cell - Pearson (mean)\"] = np.mean(cell_r)\n",
    "    ct_stats_dict[ct][\"Cell - Pearson (median)\"] = np.median(cell_r)\n",
    "    ct_stats_dict[ct][\"Cell - Spearman (mean)\"] = np.mean(cell_s)\n",
    "    ct_stats_dict[ct][\"Cell - Spearman (median)\"] = np.mean(cell_s)\n",
    "    ct_stats_dict[ct][\"Cell - R2 (mean)\"] = np.mean(cell_r2)\n",
    "    ct_stats_dict[ct][\"Cell - R2 (median)\"] = np.median(cell_r2)\n",
    "    ct_stats_dict[ct][\"Cell - MAE (mean)\"] = np.mean(cell_mae)\n",
    "    ct_stats_dict[ct][\"Cell - RMSE (mean)\"] = np.mean(cell_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0637d3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(save_dir, \"test_evaluation_stats_bycelltype.pkl\"), 'wb') as f:\n",
    "    pickle.dump(ct_stats_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509368f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cell type performances\n",
    "\n",
    "with open(os.path.join(save_dir, \"test_evaluation_stats_bycelltype.pkl\"), 'rb') as handle:\n",
    "    ct_stats_dict = pickle.load(handle)\n",
    "\n",
    "columns_to_plot = [\"Cell - Pearson (median)\", \"Cell - Spearman (median)\", \"Cell - R2 (median)\"]\n",
    "    \n",
    "#--------------------------------\n",
    "metric_col = []\n",
    "ct_col = []\n",
    "val_col = []\n",
    "\n",
    "for col in columns_to_plot:\n",
    "    for ct in ct_stats_dict.keys():\n",
    "        val = ct_stats_dict[ct][col]\n",
    "        \n",
    "        metric_col.append(col)\n",
    "        ct_col.append(ct)\n",
    "        val_col.append(val)\n",
    "\n",
    "plot_df = pd.DataFrame(np.vstack((metric_col, ct_col, val_col)).T, columns=[\"Metric\",\"Cell type\",\"Value\"])\n",
    "plot_df[\"Value\"] = plot_df[\"Value\"].astype(float)\n",
    "\n",
    "# plot\n",
    "fig, ax = plt.subplots(figsize=(12,4))\n",
    "sns.barplot(plot_df, x=\"Cell type\", y=\"Value\", hue=\"Metric\", palette=\"Reds\", ax=ax)\n",
    "sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 0.7))\n",
    "plt.title(save_dir.split(\"/\")[-2], fontsize=14)\n",
    "plt.xticks(rotation=30, ha='right', fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.xlabel(\"Cell type\", fontsize=14)\n",
    "plt.ylabel(\"Metric Value\", fontsize=14)\n",
    "plt.setp(ax.get_legend().get_texts(), fontsize='14')\n",
    "plt.setp(ax.get_legend().get_title(), fontsize='16')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ba84bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cell type performances\n",
    "\n",
    "columns_to_plot = [\"Gene - Pearson (median)\", \"Gene - Spearman (median)\", \"Gene - R2 (median)\"]\n",
    "    \n",
    "plot_df[\"Value\"] = plot_df[\"Value\"].astype(float)\n",
    "\n",
    "# plot\n",
    "fig, ax = plt.subplots(figsize=(12,4))\n",
    "sns.barplot(plot_df, x=\"Cell type\", y=\"Value\", hue=\"Metric\", palette=\"Reds\", ax=ax)\n",
    "sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 0.7))\n",
    "plt.title(save_dir.split(\"/\")[-2], fontsize=14)\n",
    "plt.xticks(rotation=30, ha='right', fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.xlabel(\"Cell type\", fontsize=14)\n",
    "plt.ylabel(\"Metric Value\", fontsize=14)\n",
    "plt.setp(ax.get_legend().get_texts(), fontsize='14')\n",
    "plt.setp(ax.get_legend().get_title(), fontsize='16')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c9242e",
   "metadata": {},
   "source": [
    "# Perturbation Modeling Figures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9a4a58",
   "metadata": {},
   "source": [
    "## Subgraph steering validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5eab021",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# filename = \"batch_steer_mean_10steps_test_actualtarget\"\n",
    "# filename = \"batch_steer_mean_10steps_test_predictedtarget\"\n",
    "\n",
    "filename = \"batch_steer_cell_10steps_test_actualtarget\"\n",
    "# filename = \"batch_steer_cell_10steps_test_predictedtarget\"\n",
    "\n",
    "save_dir = \"/labs/abrunet1/Eric/GNNPerturbation/results/gnn/expression_100per_2hop_2C0aug_200delaunay_expressionFeat_TNP_NoneInject/weightedl1_1en04\"\n",
    "\n",
    "#------------------------------------------------------\n",
    "\n",
    "# read in results\n",
    "stats_df = pd.read_csv(os.path.join(save_dir, f\"{filename}.csv\"))\n",
    "\n",
    "# make plots\n",
    "for value in [\"Pearson\", \"Spearman\", \"MAE\"]:\n",
    "    \n",
    "    # plot densities\n",
    "    fig, ax = plt.subplots(figsize=(6,4))\n",
    "    sns.kdeplot(stats_df[stats_df[\"Type\"]==\"Perturbed\"], x=value, hue=\"Prop\", ax=ax)\n",
    "    sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 0.7))\n",
    "    #plt.title(save_dir.split(\"/\")[-2], fontsize=14)\n",
    "    plt.xticks(rotation=30, ha='right', fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    for ax in plt.gcf().axes:\n",
    "        l = ax.get_xlabel()\n",
    "        ax.set_xlabel(l, fontsize=16)\n",
    "        l = ax.get_ylabel()\n",
    "        ax.set_ylabel(l, fontsize=16)\n",
    "    ax.get_legend().set_title(\"Steering\")\n",
    "    plt.setp(ax.get_legend().get_texts(), fontsize='14')\n",
    "    plt.setp(ax.get_legend().get_title(), fontsize='16')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"plots/perturbation/{filename}_density.pdf\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # plot line with confidence interval\n",
    "    fig, ax = plt.subplots(figsize=(6,4))\n",
    "    sns.lineplot(stats_df[stats_df[\"Type\"]==\"Perturbed\"], x=\"Prop\", y=value,\n",
    "                 ci=95, color='k', ax=ax)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    for ax in plt.gcf().axes:\n",
    "        l = ax.get_xlabel()\n",
    "        #ax.set_xlabel(l, fontsize=16)\n",
    "        ax.set_xlabel(\"Steering\", fontsize=16)\n",
    "        l = ax.get_ylabel()\n",
    "        ax.set_ylabel(l, fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"plots/perturbation/{filename}.pdf\", bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861a50d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99e8659",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9184a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c1d9cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed337ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matched differences\n",
    "pearson_diffs = stats_df[stats_df[\"Type\"]==\"Perturbed\"][\"Pearson\"].values - stats_df[stats_df[\"Type\"]==\"Start\"][\"Pearson\"].values\n",
    "spearman_diffs = stats_df[stats_df[\"Type\"]==\"Perturbed\"][\"Spearman\"].values - stats_df[stats_df[\"Type\"]==\"Start\"][\"Spearman\"].values\n",
    "mae_diffs = stats_df[stats_df[\"Type\"]==\"Perturbed\"][\"MAE\"].values - stats_df[stats_df[\"Type\"]==\"Start\"][\"MAE\"].values\n",
    "        \n",
    "for diffs in [pearson_diffs, spearman_diffs, mae_diffs]:\n",
    "    \n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(6,4))\n",
    "    sns.kdeplot(x=diffs, hue=stats_df[stats_df[\"Type\"]==\"Perturbed\"][\"Prop\"], ax=ax)\n",
    "    #plt.title(save_dir.split(\"/\")[-2], fontsize=14)\n",
    "    plt.xticks(rotation=30, ha='right', fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig(\"plots/perturbation/steering_complete_test.pdf\", bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21abc3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(stats_df[\"Prop\"].astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca8580a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "sns.kdeplot(stats_df[stats_df[\"Prop\"]==1.0], x=\"MAE\", hue=\"Type\", ax=ax)\n",
    "sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 0.7))\n",
    "#plt.title(save_dir.split(\"/\")[-2], fontsize=14)\n",
    "plt.xticks(rotation=30, ha='right', fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.setp(ax.get_legend().get_texts(), fontsize='14')\n",
    "plt.setp(ax.get_legend().get_title(), fontsize='16')\n",
    "for ax in plt.gcf().axes:\n",
    "    l = ax.get_xlabel()\n",
    "    ax.set_xlabel(l, fontsize=16)\n",
    "    l = ax.get_ylabel()\n",
    "    ax.set_ylabel(l, fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"plots/perturbation/steering_complete_test.pdf\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53956cbc",
   "metadata": {},
   "source": [
    "## Cross-dataset (OOD) graph steering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40cafd1",
   "metadata": {},
   "source": [
    "### Androvic et al. LPC injury"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa441bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"injuryOOD_batch_steer_cell_10steps_test_actualtarget\"\n",
    "\n",
    "save_dir = \"/labs/abrunet1/Eric/GNNPerturbation/results/gnn/expression_100per_2hop_2C0aug_200delaunay_expressionFeat_TNP_NoneInject/weightedl1_1en04\"\n",
    "\n",
    "#------------------------------------------------------\n",
    "\n",
    "# read in results\n",
    "stats_df = pd.read_csv(os.path.join(save_dir, f\"{filename}.csv\"))\n",
    "\n",
    "# make plots\n",
    "for value in [\"Pearson\", \"Spearman\", \"MAE\"]:\n",
    "    \n",
    "    # plot densities\n",
    "    fig, ax = plt.subplots(figsize=(6,4))\n",
    "    sns.kdeplot(stats_df[stats_df[\"Type\"]==\"Perturbed\"], x=value, hue=\"Prop\", ax=ax)\n",
    "    sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 0.7))\n",
    "    #plt.title(save_dir.split(\"/\")[-2], fontsize=14)\n",
    "    plt.xticks(rotation=30, ha='right', fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    for ax in plt.gcf().axes:\n",
    "        l = ax.get_xlabel()\n",
    "        ax.set_xlabel(l, fontsize=16)\n",
    "        l = ax.get_ylabel()\n",
    "        ax.set_ylabel(l, fontsize=16)\n",
    "    ax.get_legend().set_title(\"Steering\")\n",
    "    plt.setp(ax.get_legend().get_texts(), fontsize='14')\n",
    "    plt.setp(ax.get_legend().get_title(), fontsize='16')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"plots/perturbation/{filename}_density.pdf\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # plot line with confidence interval\n",
    "    fig, ax = plt.subplots(figsize=(6,4))\n",
    "    sns.lineplot(stats_df[stats_df[\"Type\"]==\"Perturbed\"], x=\"Prop\", y=value,\n",
    "                 ci=95, color='k', ax=ax)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    for ax in plt.gcf().axes:\n",
    "        l = ax.get_xlabel()\n",
    "        #ax.set_xlabel(l, fontsize=16)\n",
    "        ax.set_xlabel(\"Steering\", fontsize=16)\n",
    "        l = ax.get_ylabel()\n",
    "        ax.set_ylabel(l, fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"plots/perturbation/{filename}.pdf\", bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36055ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "sns.kdeplot(stats_df[stats_df[\"Prop\"]==1.0], x=\"MAE\", hue=\"Type\", ax=ax)\n",
    "sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 0.7))\n",
    "#plt.title(save_dir.split(\"/\")[-2], fontsize=14)\n",
    "plt.xticks(rotation=30, ha='right', fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.setp(ax.get_legend().get_texts(), fontsize='14')\n",
    "plt.setp(ax.get_legend().get_title(), fontsize='16')\n",
    "for ax in plt.gcf().axes:\n",
    "    l = ax.get_xlabel()\n",
    "    ax.set_xlabel(l, fontsize=16)\n",
    "    l = ax.get_ylabel()\n",
    "    ax.set_ylabel(l, fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"plots/perturbation/{filename}_densityStartEnd.pdf\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76872caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"noninjuryOOD_batch_steer_cell_10steps_test_actualtarget\"\n",
    "\n",
    "save_dir = \"/labs/abrunet1/Eric/GNNPerturbation/results/gnn/expression_100per_2hop_2C0aug_200delaunay_expressionFeat_TNP_NoneInject/weightedl1_1en04\"\n",
    "\n",
    "#------------------------------------------------------\n",
    "\n",
    "# read in results\n",
    "stats_df = pd.read_csv(os.path.join(save_dir, f\"{filename}.csv\"))\n",
    "\n",
    "# make plots\n",
    "for value in [\"Pearson\", \"Spearman\", \"MAE\"]:\n",
    "    \n",
    "    # plot densities\n",
    "    fig, ax = plt.subplots(figsize=(6,4))\n",
    "    sns.kdeplot(stats_df[stats_df[\"Type\"]==\"Perturbed\"], x=value, hue=\"Prop\", ax=ax)\n",
    "    sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 0.7))\n",
    "    #plt.title(save_dir.split(\"/\")[-2], fontsize=14)\n",
    "    plt.xticks(rotation=30, ha='right', fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    for ax in plt.gcf().axes:\n",
    "        l = ax.get_xlabel()\n",
    "        ax.set_xlabel(l, fontsize=16)\n",
    "        l = ax.get_ylabel()\n",
    "        ax.set_ylabel(l, fontsize=16)\n",
    "    ax.get_legend().set_title(\"Steering\")\n",
    "    plt.setp(ax.get_legend().get_texts(), fontsize='14')\n",
    "    plt.setp(ax.get_legend().get_title(), fontsize='16')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"plots/perturbation/{filename}_density.pdf\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # plot line with confidence interval\n",
    "    fig, ax = plt.subplots(figsize=(6,4))\n",
    "    sns.lineplot(stats_df[stats_df[\"Type\"]==\"Perturbed\"], x=\"Prop\", y=value,\n",
    "                 ci=95, color='k', ax=ax)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    for ax in plt.gcf().axes:\n",
    "        l = ax.get_xlabel()\n",
    "        #ax.set_xlabel(l, fontsize=16)\n",
    "        ax.set_xlabel(\"Steering\", fontsize=16)\n",
    "        l = ax.get_ylabel()\n",
    "        ax.set_ylabel(l, fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"plots/perturbation/{filename}.pdf\", bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259eb660",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "sns.kdeplot(stats_df[stats_df[\"Prop\"]==1.0], x=\"MAE\", hue=\"Type\", ax=ax)\n",
    "sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 0.7))\n",
    "#plt.title(save_dir.split(\"/\")[-2], fontsize=14)\n",
    "plt.xticks(rotation=30, ha='right', fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.setp(ax.get_legend().get_texts(), fontsize='14')\n",
    "plt.setp(ax.get_legend().get_title(), fontsize='16')\n",
    "for ax in plt.gcf().axes:\n",
    "    l = ax.get_xlabel()\n",
    "    ax.set_xlabel(l, fontsize=16)\n",
    "    l = ax.get_ylabel()\n",
    "    ax.set_ylabel(l, fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"plots/perturbation/{filename}_densityStartEnd.pdf\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a8f896",
   "metadata": {},
   "source": [
    "### Allen et al. LPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8efb690",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"oldlpsOOD_batch_steer_cell_10steps_test_actualtarget\"\n",
    "\n",
    "save_dir = \"/labs/abrunet1/Eric/GNNPerturbation/results/gnn/expression_100per_2hop_2C0aug_200delaunay_expressionFeat_TNP_NoneInject/weightedl1_1en04\"\n",
    "\n",
    "#------------------------------------------------------\n",
    "\n",
    "# read in results\n",
    "stats_df = pd.read_csv(os.path.join(save_dir, f\"{filename}.csv\"))\n",
    "\n",
    "# make plots\n",
    "for value in [\"Pearson\", \"Spearman\", \"MAE\"]:\n",
    "    \n",
    "    # plot densities\n",
    "    fig, ax = plt.subplots(figsize=(6,4))\n",
    "    sns.kdeplot(stats_df[stats_df[\"Type\"]==\"Perturbed\"], x=value, hue=\"Prop\", ax=ax)\n",
    "    sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 0.7))\n",
    "    #plt.title(save_dir.split(\"/\")[-2], fontsize=14)\n",
    "    plt.xticks(rotation=30, ha='right', fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    for ax in plt.gcf().axes:\n",
    "        l = ax.get_xlabel()\n",
    "        ax.set_xlabel(l, fontsize=16)\n",
    "        l = ax.get_ylabel()\n",
    "        ax.set_ylabel(l, fontsize=16)\n",
    "    ax.get_legend().set_title(\"Steering\")\n",
    "    plt.setp(ax.get_legend().get_texts(), fontsize='14')\n",
    "    plt.setp(ax.get_legend().get_title(), fontsize='16')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"plots/perturbation/{filename}_density.pdf\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # plot line with confidence interval\n",
    "    fig, ax = plt.subplots(figsize=(6,4))\n",
    "    sns.lineplot(stats_df[stats_df[\"Type\"]==\"Perturbed\"], x=\"Prop\", y=value,\n",
    "                 ci=95, color='k', ax=ax)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    for ax in plt.gcf().axes:\n",
    "        l = ax.get_xlabel()\n",
    "        #ax.set_xlabel(l, fontsize=16)\n",
    "        ax.set_xlabel(\"Steering\", fontsize=16)\n",
    "        l = ax.get_ylabel()\n",
    "        ax.set_ylabel(l, fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"plots/perturbation/{filename}.pdf\", bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe76f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "sns.kdeplot(stats_df[stats_df[\"Prop\"]==1.0], x=\"MAE\", hue=\"Type\", ax=ax)\n",
    "sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 0.7))\n",
    "#plt.title(save_dir.split(\"/\")[-2], fontsize=14)\n",
    "plt.xticks(rotation=30, ha='right', fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.setp(ax.get_legend().get_texts(), fontsize='14')\n",
    "plt.setp(ax.get_legend().get_title(), fontsize='16')\n",
    "for ax in plt.gcf().axes:\n",
    "    l = ax.get_xlabel()\n",
    "    ax.set_xlabel(l, fontsize=16)\n",
    "    l = ax.get_ylabel()\n",
    "    ax.set_ylabel(l, fontsize=16)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"plots/perturbation/steering_complete_test.pdf\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef97df4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"oldnonlpsOOD_batch_steer_cell_10steps_test_actualtarget\"\n",
    "\n",
    "save_dir = \"/labs/abrunet1/Eric/GNNPerturbation/results/gnn/expression_100per_2hop_2C0aug_200delaunay_expressionFeat_TNP_NoneInject/weightedl1_1en04\"\n",
    "\n",
    "#------------------------------------------------------\n",
    "\n",
    "# read in results\n",
    "stats_df = pd.read_csv(os.path.join(save_dir, f\"{filename}.csv\"))\n",
    "\n",
    "# make plots\n",
    "for value in [\"Pearson\", \"Spearman\", \"MAE\"]:\n",
    "    \n",
    "    # plot densities\n",
    "    fig, ax = plt.subplots(figsize=(6,4))\n",
    "    sns.kdeplot(stats_df[stats_df[\"Type\"]==\"Perturbed\"], x=value, hue=\"Prop\", ax=ax)\n",
    "    sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 0.7))\n",
    "    #plt.title(save_dir.split(\"/\")[-2], fontsize=14)\n",
    "    plt.xticks(rotation=30, ha='right', fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    for ax in plt.gcf().axes:\n",
    "        l = ax.get_xlabel()\n",
    "        ax.set_xlabel(l, fontsize=16)\n",
    "        l = ax.get_ylabel()\n",
    "        ax.set_ylabel(l, fontsize=16)\n",
    "    ax.get_legend().set_title(\"Steering\")\n",
    "    plt.setp(ax.get_legend().get_texts(), fontsize='14')\n",
    "    plt.setp(ax.get_legend().get_title(), fontsize='16')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"plots/perturbation/{filename}_density.pdf\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # plot line with confidence interval\n",
    "    fig, ax = plt.subplots(figsize=(6,4))\n",
    "    sns.lineplot(stats_df[stats_df[\"Type\"]==\"Perturbed\"], x=\"Prop\", y=value,\n",
    "                 ci=95, color='k', ax=ax)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    for ax in plt.gcf().axes:\n",
    "        l = ax.get_xlabel()\n",
    "        #ax.set_xlabel(l, fontsize=16)\n",
    "        ax.set_xlabel(\"Steering\", fontsize=16)\n",
    "        l = ax.get_ylabel()\n",
    "        ax.set_ylabel(l, fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"plots/perturbation/{filename}.pdf\", bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5753a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "sns.kdeplot(stats_df[stats_df[\"Prop\"]==1.0], x=\"MAE\", hue=\"Type\", ax=ax)\n",
    "sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 0.7))\n",
    "#plt.title(save_dir.split(\"/\")[-2], fontsize=14)\n",
    "plt.xticks(rotation=30, ha='right', fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.setp(ax.get_legend().get_texts(), fontsize='14')\n",
    "plt.setp(ax.get_legend().get_title(), fontsize='16')\n",
    "for ax in plt.gcf().axes:\n",
    "    l = ax.get_xlabel()\n",
    "    ax.set_xlabel(l, fontsize=16)\n",
    "    l = ax.get_ylabel()\n",
    "    ax.set_ylabel(l, fontsize=16)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"plots/perturbation/steering_complete_test.pdf\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7de258",
   "metadata": {},
   "source": [
    "### Kukanja et al. EAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01452320",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"eaeOOD_batch_steer_cell_10steps_test_actualtarget\"\n",
    "\n",
    "save_dir = \"/labs/abrunet1/Eric/GNNPerturbation/results/gnn/expression_100per_2hop_2C0aug_200delaunay_expressionFeat_TNP_NoneInject/weightedl1_1en04\"\n",
    "\n",
    "#------------------------------------------------------\n",
    "\n",
    "# read in results\n",
    "stats_df = pd.read_csv(os.path.join(save_dir, f\"{filename}.csv\"))\n",
    "\n",
    "# make plots\n",
    "for value in [\"Pearson\", \"Spearman\", \"MAE\"]:\n",
    "    \n",
    "    # plot densities\n",
    "    fig, ax = plt.subplots(figsize=(6,4))\n",
    "    sns.kdeplot(stats_df[stats_df[\"Type\"]==\"Perturbed\"], x=value, hue=\"Prop\", ax=ax)\n",
    "    sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 0.7))\n",
    "    #plt.title(save_dir.split(\"/\")[-2], fontsize=14)\n",
    "    plt.xticks(rotation=30, ha='right', fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    for ax in plt.gcf().axes:\n",
    "        l = ax.get_xlabel()\n",
    "        ax.set_xlabel(l, fontsize=16)\n",
    "        l = ax.get_ylabel()\n",
    "        ax.set_ylabel(l, fontsize=16)\n",
    "    ax.get_legend().set_title(\"Steering\")\n",
    "    plt.setp(ax.get_legend().get_texts(), fontsize='14')\n",
    "    plt.setp(ax.get_legend().get_title(), fontsize='16')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"plots/perturbation/{filename}_density.pdf\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # plot line with confidence interval\n",
    "    fig, ax = plt.subplots(figsize=(6,4))\n",
    "    sns.lineplot(stats_df[stats_df[\"Type\"]==\"Perturbed\"], x=\"Prop\", y=value,\n",
    "                 ci=95, color='k', ax=ax)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    for ax in plt.gcf().axes:\n",
    "        l = ax.get_xlabel()\n",
    "        #ax.set_xlabel(l, fontsize=16)\n",
    "        ax.set_xlabel(\"Steering\", fontsize=16)\n",
    "        l = ax.get_ylabel()\n",
    "        ax.set_ylabel(l, fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"plots/perturbation/{filename}.pdf\", bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d025a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "sns.kdeplot(stats_df[stats_df[\"Prop\"]==1.0], x=\"MAE\", hue=\"Type\", ax=ax)\n",
    "sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 0.7))\n",
    "#plt.title(save_dir.split(\"/\")[-2], fontsize=14)\n",
    "plt.xticks(rotation=30, ha='right', fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.setp(ax.get_legend().get_texts(), fontsize='14')\n",
    "plt.setp(ax.get_legend().get_title(), fontsize='16')\n",
    "for ax in plt.gcf().axes:\n",
    "    l = ax.get_xlabel()\n",
    "    ax.set_xlabel(l, fontsize=16)\n",
    "    l = ax.get_ylabel()\n",
    "    ax.set_ylabel(l, fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"plots/perturbation/{filename}_densityStartEnd.pdf\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5ad9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"noneaeOOD_batch_steer_cell_10steps_test_actualtarget\"\n",
    "\n",
    "save_dir = \"/labs/abrunet1/Eric/GNNPerturbation/results/gnn/expression_100per_2hop_2C0aug_200delaunay_expressionFeat_TNP_NoneInject/weightedl1_1en04\"\n",
    "\n",
    "#------------------------------------------------------\n",
    "\n",
    "# read in results\n",
    "stats_df = pd.read_csv(os.path.join(save_dir, f\"{filename}.csv\"))\n",
    "\n",
    "# make plots\n",
    "for value in [\"Pearson\", \"Spearman\", \"MAE\"]:\n",
    "    \n",
    "    # plot densities\n",
    "    fig, ax = plt.subplots(figsize=(6,4))\n",
    "    sns.kdeplot(stats_df[stats_df[\"Type\"]==\"Perturbed\"], x=value, hue=\"Prop\", ax=ax)\n",
    "    sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 0.7))\n",
    "    #plt.title(save_dir.split(\"/\")[-2], fontsize=14)\n",
    "    plt.xticks(rotation=30, ha='right', fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    for ax in plt.gcf().axes:\n",
    "        l = ax.get_xlabel()\n",
    "        ax.set_xlabel(l, fontsize=16)\n",
    "        l = ax.get_ylabel()\n",
    "        ax.set_ylabel(l, fontsize=16)\n",
    "    ax.get_legend().set_title(\"Steering\")\n",
    "    plt.setp(ax.get_legend().get_texts(), fontsize='14')\n",
    "    plt.setp(ax.get_legend().get_title(), fontsize='16')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"plots/perturbation/{filename}_density.pdf\", bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # plot line with confidence interval\n",
    "    fig, ax = plt.subplots(figsize=(6,4))\n",
    "    sns.lineplot(stats_df[stats_df[\"Type\"]==\"Perturbed\"], x=\"Prop\", y=value,\n",
    "                 errorbar=('ci', 95), color='k', ax=ax)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    for ax in plt.gcf().axes:\n",
    "        l = ax.get_xlabel()\n",
    "        #ax.set_xlabel(l, fontsize=16)\n",
    "        ax.set_xlabel(\"Steering\", fontsize=16)\n",
    "        l = ax.get_ylabel()\n",
    "        ax.set_ylabel(l, fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"plots/perturbation/{filename}.pdf\", bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e7954b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "sns.kdeplot(stats_df[stats_df[\"Prop\"]==1.0], x=\"MAE\", hue=\"Type\", ax=ax)\n",
    "sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 0.7))\n",
    "#plt.title(save_dir.split(\"/\")[-2], fontsize=14)\n",
    "plt.xticks(rotation=30, ha='right', fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.setp(ax.get_legend().get_texts(), fontsize='14')\n",
    "plt.setp(ax.get_legend().get_title(), fontsize='16')\n",
    "for ax in plt.gcf().axes:\n",
    "    l = ax.get_xlabel()\n",
    "    ax.set_xlabel(l, fontsize=16)\n",
    "    l = ax.get_ylabel()\n",
    "    ax.set_ylabel(l, fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"plots/perturbation/{filename}_densityStartEnd.pdf\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81a4678",
   "metadata": {},
   "source": [
    "## Representation Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15c45586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "train_ids = [\n",
    "    ['1','101','14','19','30','38','42','46','53','61','7','70','75','80','86','97'], # aging coronal\n",
    "    ['2','34','39','62','68'], # aging sagittal\n",
    "    None, # exercise\n",
    "    None, # reprogramming\n",
    "#     ['MsBrainAgingSpatialDonor_10_0', 'MsBrainAgingSpatialDonor_10_1', 'MsBrainAgingSpatialDonor_10_2', 'MsBrainAgingSpatialDonor_11_0', 'MsBrainAgingSpatialDonor_11_1', 'MsBrainAgingSpatialDonor_11_2', 'MsBrainAgingSpatialDonor_12_0', 'MsBrainAgingSpatialDonor_12_1', 'MsBrainAgingSpatialDonor_13_1', 'MsBrainAgingSpatialDonor_13_2', 'MsBrainAgingSpatialDonor_14_1', 'MsBrainAgingSpatialDonor_15_0', 'MsBrainAgingSpatialDonor_15_1', 'MsBrainAgingSpatialDonor_16_0', 'MsBrainAgingSpatialDonor_16_1', 'MsBrainAgingSpatialDonor_17_0', 'MsBrainAgingSpatialDonor_17_1', 'MsBrainAgingSpatialDonor_18_0', 'MsBrainAgingSpatialDonor_18_1', 'MsBrainAgingSpatialDonor_19_0', 'MsBrainAgingSpatialDonor_19_1', 'MsBrainAgingSpatialDonor_19_2', 'MsBrainAgingSpatialDonor_2_0', 'MsBrainAgingSpatialDonor_2_1', 'MsBrainAgingSpatialDonor_3_0', 'MsBrainAgingSpatialDonor_3_1', 'MsBrainAgingSpatialDonor_4_0', 'MsBrainAgingSpatialDonor_4_1', 'MsBrainAgingSpatialDonor_4_2', 'MsBrainAgingSpatialDonor_5_0', 'MsBrainAgingSpatialDonor_5_1', 'MsBrainAgingSpatialDonor_5_2', 'MsBrainAgingSpatialDonor_6_0', 'MsBrainAgingSpatialDonor_6_1', 'MsBrainAgingSpatialDonor_6_2', 'MsBrainAgingSpatialDonor_7_0', 'MsBrainAgingSpatialDonor_7_1', 'MsBrainAgingSpatialDonor_7_2', 'MsBrainAgingSpatialDonor_8_0', 'MsBrainAgingSpatialDonor_8_1', 'MsBrainAgingSpatialDonor_8_2', 'MsBrainAgingSpatialDonor_9_1', 'MsBrainAgingSpatialDonor_9_2'], # allen\n",
    "#     None, # androvic\n",
    "#     ['CNTRL_PEAK_B_R2', 'CNTRL_PEAK_B_R3', 'CNTRL_PEAK_B_R4', 'EAE_PEAK_B_R2', 'EAE_PEAK_B_R3', 'EAE_PEAK_B_R4'], # kukanja\n",
    "#     ['Middle1', 'Old1', 'Old2', 'Young1', 'Young2'], # pilot\n",
    "]\n",
    "\n",
    "# test\n",
    "test_ids = [\n",
    "    [\"11\",\"33\",\"57\",\"93\"], # aging coronal\n",
    "    ['81'], # aging sagittal\n",
    "    [], # exercise\n",
    "    [], # reprogramming\n",
    "#     [\"MsBrainAgingSpatialDonor_13_0\",\"MsBrainAgingSpatialDonor_9_0\",\"MsBrainAgingSpatialDonor_14_0\",\"MsBrainAgingSpatialDonor_1_0\"], # allen\n",
    "#     [], # androvic\n",
    "#     ['CNTRL_PEAK_B_R1', 'EAE_PEAK_B_R1'], # kukanja\n",
    "#     [\"Middle2\"], # pilot\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f337b30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get params\n",
    "k_hop = 2\n",
    "augment_hop = 2\n",
    "center_celltypes = [\"T cell\",\"NSC\",\"Pericyte\"]\n",
    "node_feature = \"expression\"\n",
    "loss = \"weightedl1\"\n",
    "learning_rate = 0.0001\n",
    "use_model = \"model\"\n",
    "#use_model = \"best_model\"\n",
    "inject_feature = \"center_celltype\"\n",
    "inject=False\n",
    "\n",
    "#--------------------------------------------------------------\n",
    "\n",
    "if inject is False:\n",
    "    inject_feature = None\n",
    "\n",
    "# init test data\n",
    "test_dataset = SpatialAgingCellDataset(subfolder_name=\"test\",\n",
    "                                       target=\"expression\",\n",
    "                                       k_hop=k_hop,\n",
    "                                       augment_hop=augment_hop,\n",
    "                                       node_feature=node_feature,\n",
    "                                       inject_feature=inject_feature,\n",
    "                                       num_cells_per_ct_id=100,\n",
    "                                       center_celltypes=center_celltypes,\n",
    "                                  use_ids=train_ids)\n",
    "\n",
    "# init train data\n",
    "train_dataset = SpatialAgingCellDataset(subfolder_name=\"train\",\n",
    "                                        target=\"expression\",\n",
    "                                        k_hop=k_hop,\n",
    "                                        augment_hop=augment_hop,\n",
    "                                        node_feature=node_feature,\n",
    "                                        inject_feature=inject_feature,\n",
    "                                        num_cells_per_ct_id=100,\n",
    "                                        center_celltypes=center_celltypes,\n",
    "                                use_ids=test_ids)\n",
    "\n",
    "# concatenate datasets\n",
    "all_dataset = torch.utils.data.ConcatDataset([train_dataset, test_dataset])\n",
    "\n",
    "# define data loaders\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "all_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# LOAD MODELS\n",
    "model_dirname = loss+f\"_{learning_rate:.0e}\".replace(\"-\",\"n\")\n",
    "save_dir = os.path.join(\"results/gnn\",train_dataset.processed_dir.split(\"/\")[-2],model_dirname)\n",
    "\n",
    "# TRAIN MODEL\n",
    "# init model\n",
    "if inject is True:\n",
    "    model = GNN(hidden_channels=64,\n",
    "                input_dim=int(train_dataset.get(0).x.shape[1]),\n",
    "                output_dim=len(train_dataset.get(0).y), # added for multivariate targets\n",
    "                inject_dim=int(train_dataset.get(0).inject.shape[1]), # added for injecting features into last layer (after pooling)\n",
    "                method=\"GIN\", pool=\"add\", num_layers=k_hop)\n",
    "else:\n",
    "    model = GNN(hidden_channels=64,\n",
    "            input_dim=int(train_dataset.get(0).x.shape[1]),\n",
    "            output_dim=len(train_dataset.get(0).y), # added for multivariate targets\n",
    "            method=\"GIN\", pool=\"add\", num_layers=k_hop)\n",
    "\n",
    "# load model weights\n",
    "model.load_state_dict(torch.load(os.path.join(save_dir, f\"{use_model}.pth\"),\n",
    "                                map_location=torch.device('cpu')))\n",
    "\n",
    "# # ALL MODEL\n",
    "# # init model\n",
    "# all_model = GNN(hidden_channels=16,\n",
    "#             input_dim=int(test_dataset.get(0).x.shape[1]),\n",
    "#             method=\"GIN\", pool=\"add\", num_layers=k_hop)\n",
    "\n",
    "# # load model weights\n",
    "# all_model.load_state_dict(torch.load(os.path.join(save_dir, f\"all_{use_model}.pth\")))\n",
    "\n",
    "from torch_geometric import profile\n",
    "profile.count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc5a573c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace final linear layer with identity layer\n",
    "model.lin = torch.nn.Identity()\n",
    "\n",
    "# # remove last layer from model\n",
    "# rep_model = torch_geometric.nn.Sequential(*list(model.children())[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5fc2378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# center cell type as label\n",
    "\n",
    "embeddings = []\n",
    "avg_expression_baseline = []\n",
    "celltypes = []\n",
    "regions = []\n",
    "ages = []\n",
    "conditions = []\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for data in test_loader:\n",
    "    \n",
    "    # get graph embedding\n",
    "    if inject is False:\n",
    "        out = model(data.x, data.edge_index, data.batch, None)\n",
    "    else:\n",
    "        out = model(data.x, data.edge_index, data.batch, data.inject)\n",
    "        \n",
    "    # node embeddings\n",
    "    #a = torch_geometric.utils.get_embeddings(model, data.x, data.edge_index, data.batch, None)\n",
    "    \n",
    "    # get mean expression per graph\n",
    "    mean_expns = []\n",
    "    for bi in np.unique(data.batch):\n",
    "        mean_expns.append(torch.mean(data.x[data.batch==bi,:], axis=0))\n",
    "    \n",
    "    # append embeddings, baselines, labels\n",
    "    embeddings.append(out)\n",
    "    avg_expression_baseline.append(torch.stack(mean_expns))\n",
    "    celltypes = np.concatenate((celltypes,np.concatenate(data.center_celltype)))\n",
    "    regions = np.concatenate((regions,np.concatenate(data.region)))\n",
    "    ages = np.concatenate((ages,np.concatenate(data.age)))\n",
    "    conditions = np.concatenate((conditions,np.concatenate(data.condition)))\n",
    "    \n",
    "# convert to numpy and format nicely\n",
    "embeddings = torch.cat(embeddings, dim=0).detach().numpy()\n",
    "avg_expression_baseline = torch.cat(avg_expression_baseline, dim=0).detach().numpy()\n",
    "\n",
    "# save \"dataset\"\n",
    "save_dict = {\n",
    "    \"embeddings\": embeddings,\n",
    "    \"avg_expression_baseline\": avg_expression_baseline,\n",
    "    \"celltypes\": celltypes,\n",
    "    \"regions\": regions,\n",
    "    \"ages\": ages,\n",
    "    \"conditions\": conditions,\n",
    "}\n",
    "with open(os.path.join(save_dir, \"representation_to_predict_celltype_dict.pkl\"), 'wb') as f:\n",
    "    pickle.dump(save_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f1da55",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_str = \"regions\"\n",
    "\n",
    "\n",
    "\n",
    "# load results\n",
    "with open(os.path.join(save_dir, \"representation_to_predict_celltype_dict.pkl\"), 'rb') as f:\n",
    "    save_dict = pickle.load(f)\n",
    "\n",
    "embeddings = save_dict[\"embeddings\"]\n",
    "avg_expression_baseline = save_dict[\"avg_expression_baseline\"]\n",
    "labels = save_dict[label_str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894d51ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train classifiers to predict label\n",
    "\n",
    "def get_cross_val_predictions (x, y, method='logistic', dim=np.inf):\n",
    "    '''\n",
    "    Trains a model to predict y from x\n",
    "    '''\n",
    "    from sklearn.model_selection import cross_val_predict\n",
    "    \n",
    "    # init model\n",
    "    if method == \"logistic\":\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        clf = LogisticRegression(max_iter=300, solver=\"sag\", n_jobs=4)\n",
    "    elif method == \"lasso\":\n",
    "        from sklearn.linear_model import Lasso\n",
    "        reg = Lasso(max_iter=300, alpha=1.0)\n",
    "    \n",
    "    # dimensionality reduction\n",
    "    if x.shape[1] > dim:\n",
    "        from sklearn.decomposition import PCA\n",
    "        pca = PCA(n_components=dim)\n",
    "        x = pca.fit_transform(x)\n",
    "    \n",
    "    if method == 'logistic':\n",
    "    \n",
    "        # get class probabilities\n",
    "        predictions_proba = cross_val_predict(clf, x, y, cv=5, method='predict_proba')\n",
    "\n",
    "        # get class predictions\n",
    "        predictions = np.argmax(predictions_proba, axis=1)\n",
    "        clf.fit(x,y)\n",
    "        mapper = {i: l for i, l in enumerate(clf.classes_)}\n",
    "        predictions = np.vectorize(mapper.get)(predictions)\n",
    "        \n",
    "    elif method == \"lasso\":\n",
    "        \n",
    "        # get predictions\n",
    "        predictions = cross_val_predict(reg, x, y, cv=5)\n",
    "        predictions_proba = None\n",
    "        \n",
    "    \n",
    "    return (predictions, predictions_proba)\n",
    "\n",
    "# embeddings predict\n",
    "emb_pred, emb_proba = get_cross_val_predictions (embeddings, labels, method='logistic')\n",
    "\n",
    "# baseline predict\n",
    "bas_pred, bas_proba = get_cross_val_predictions (avg_expression_baseline, labels, method='logistic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3699081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_lst = [emb_pred, emb_proba, bas_pred, bas_proba]\n",
    "# import pickle\n",
    "# with open(os.path.join(save_dir, \"logistic_celltype_results.pkl\"), 'wb') as f:\n",
    "#     pickle.dump(results_lst, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a31064e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate performance\n",
    "from sklearn.metrics import balanced_accuracy_score, average_precision_score, top_k_accuracy_score, classification_report\n",
    "\n",
    "\n",
    "\n",
    "print(\"Embedding:\")\n",
    "\n",
    "value = average_precision_score(labels, emb_proba)\n",
    "print(f\"Average Precision: {round(value,3)}\")\n",
    "\n",
    "value = balanced_accuracy_score(labels, emb_pred)\n",
    "print(f\"Balanced Accuracy: {round(value,3)}\")\n",
    "\n",
    "value = top_k_accuracy_score(labels, emb_proba, k=1)\n",
    "print(f\"Top 1 Accuracy: {round(value,3)}\")\n",
    "\n",
    "value = top_k_accuracy_score(labels, emb_proba, k=2)\n",
    "print(f\"Top 2 Accuracy: {round(value,3)}\")\n",
    "\n",
    "value = top_k_accuracy_score(labels, emb_proba, k=3)\n",
    "print(f\"Top 3 Accuracy: {round(value,3)}\")\n",
    "\n",
    "embed_dict = classification_report(labels, emb_pred)\n",
    "print(embed_dict)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nBaseline:\")\n",
    "\n",
    "value = average_precision_score(labels, bas_proba)\n",
    "print(f\"Average Precision: {round(value,3)}\")\n",
    "\n",
    "value = balanced_accuracy_score(labels, bas_pred)\n",
    "print(f\"Balanced Accuracy: {round(value,3)}\")\n",
    "\n",
    "value = top_k_accuracy_score(labels, bas_proba, k=1)\n",
    "print(f\"Top 1 Accuracy: {round(value,3)}\")\n",
    "\n",
    "value = top_k_accuracy_score(labels, bas_proba, k=2)\n",
    "print(f\"Top 2 Accuracy: {round(value,3)}\")\n",
    "\n",
    "value = top_k_accuracy_score(labels, bas_proba, k=3)\n",
    "print(f\"Top 3 Accuracy: {round(value,3)}\")\n",
    "\n",
    "bas_dict = classification_report(labels, bas_pred)\n",
    "print(bas_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ce0c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate performance\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "\n",
    "print(\"Embedding:\")\n",
    "\n",
    "value = pearsonr(labels, emb_pred)[0]\n",
    "print(f\"Pearson: {round(value,3)}\")\n",
    "\n",
    "value = r2_score(labels, emb_pred)\n",
    "print(f\"R2: {round(value,3)}\")\n",
    "\n",
    "value = mean_absolute_error(labels, emb_pred)\n",
    "print(f\"MAE: {round(value,3)}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nBaseline:\")\n",
    "\n",
    "value = pearsonr(labels, bas_pred)[0]\n",
    "print(f\"Pearson: {round(value,3)}\")\n",
    "\n",
    "value = r2_score(labels, bas_pred)\n",
    "print(f\"R2: {round(value,3)}\")\n",
    "\n",
    "value = mean_absolute_error(labels, bas_pred)\n",
    "print(f\"MAE: {round(value,3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141e4d03",
   "metadata": {},
   "source": [
    "## Spot Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d944cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### spot check\n",
    "\n",
    "graph_index = 545\n",
    "\n",
    "print(test_dataset.get(graph_index).center_celltype)\n",
    "print(test_dataset.get(graph_index).center_node)\n",
    "\n",
    "from torch_geometric.utils import to_networkx\n",
    "G = to_networkx(test_dataset.get(graph_index), node_attrs=[\"celltypes\"])\n",
    "gpos = nx.spring_layout(G)\n",
    "nx.draw(G, pos=gpos)\n",
    "nx.draw_networkx_labels(G, pos=gpos)\n",
    "plt.draw()\n",
    "\n",
    "print(G.nodes[int(test_dataset.get(graph_index).center_node)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spatial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
