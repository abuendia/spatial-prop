{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b38f5d01",
   "metadata": {},
   "source": [
    "## Training and deploying a SpatialProp model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3ccc81",
   "metadata": {},
   "source": [
    "This tutorial demonstrates how to train a SpatialProp model from scratch and deploy it for scoring on a coronal mouse tissue brain section. \n",
    "\n",
    "We will make use of the `aging_coronal.h5ad` dataset from [Sun et al., 2025](https://www.nature.com/articles/s41586-024-08334-8). This dataset includes coronal brain sections from mice at 20 different ages tiling the entire lifespan. Spatial transcriptomics of 300 genes were profiled with MERFISH technology. To download the dataset, run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d11cfdf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists: ./data/aging_coronal.h5ad — skipping download.\n"
     ]
    }
   ],
   "source": [
    "! mkdir -p ./data\n",
    "! if [ ! -f ./data/aging_coronal.h5ad ]; then \\\n",
    "      echo \"Downloading aging_coronal.h5ad...\"; \\\n",
    "      wget https://zenodo.org/records/13883177/files/aging_coronal.h5ad -O ./data/aging_coronal.h5ad; \\\n",
    "    else \\\n",
    "      echo \"File already exists: ./data/aging_coronal.h5ad — skipping download.\"; \\\n",
    "    fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4db121",
   "metadata": {},
   "source": [
    "With the `spatial-prop` conda environment activated (see Installation section of [README.md](../README.md)), run the following cell to import the API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e92d311",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/abuen/miniconda3/envs/spatial/lib/python3.10/site-packages/dask/dataframe/__init__.py:31: FutureWarning: The legacy Dask DataFrame implementation is deprecated and will be removed in a future version. Set the configuration option `dataframe.query-planning` to `True` or None to enable the new Dask Dataframe implementation and silence this warning.\n",
      "  warnings.warn(\n",
      "/users/abuen/miniconda3/envs/spatial/lib/python3.10/site-packages/xarray_schema/__init__.py:1: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import DistributionNotFound, get_distribution\n",
      "/users/abuen/miniconda3/envs/spatial/lib/python3.10/site-packages/anndata/utils.py:434: FutureWarning: Importing read_text from `anndata` is deprecated. Import anndata.io.read_text instead.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scanpy as sc \n",
    "import torch\n",
    "\n",
    "from spatial_gnn.api.perturbation_api import (\n",
    "    train_perturbation_model,\n",
    "    create_perturbation_input_matrix,\n",
    "    predict_perturbation_effects, \n",
    "    predict_perturbation_effects\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35de5b61",
   "metadata": {},
   "source": [
    "### Define and train the GNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf98e008",
   "metadata": {},
   "source": [
    "Training the SpatialProp GNN requires defining the set of training arguments detailed in the [perturbation training API](../src/spatial_gnn/api/perturbation_api.py) docstring. Here we reuse the model configuration reported in the paper. \n",
    "\n",
    "Graphs are constructed using 2-hop neighbors centered around cells of all cell types, and we limit to 100 cells per cell type. We augment the training and test sets with 2-hop neighborhood graphs around each surrounding cell. Here we train the base model which does not use or predict cell type labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4611fbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = {\n",
    "    \"dataset\": \"aging_coronal\",\n",
    "    \"exp_name\": \"api_demo\",\n",
    "    \"base_path\": \"./data\",\n",
    "    \"k_hop\": 2,\n",
    "    \"augment_hop\": 2,\n",
    "    \"center_celltypes\": \"all\",\n",
    "    \"node_feature\": \"expression\",\n",
    "    \"inject_feature\": \"none\",\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"loss\": \"weightedl1\",\n",
    "    \"epochs\": 50,\n",
    "    \"normalize_total\": True,\n",
    "    \"num_cells_per_ct_id\": 100,\n",
    "    \"adata_path\": \"./data/aging_coronal.h5ad\",\n",
    "    \"predict_celltype\": False,\n",
    "    \"pool\": \"center\",\n",
    "    \"do_eval\": True,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b99178",
   "metadata": {},
   "source": [
    "The training API call will trigger construction of the graph dataset in the `./data/gnn_datasets/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf47f583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training new perturbation model from scratch...\n",
      "Model will be saved to: output/api_demo/aging_coronal_expression_2hop_2augment_expression_none/weightedl1_1en04\n",
      "Training on device: cuda\n",
      "Dataset already exists at:  ./data/gnn_datasets/aging_coronal_expression_100per_2hop_2C0aug_200delaunay_expressionFeat_all_NoneInject/test\n",
      "Finished processing test dataset\n",
      "Dataset already exists at:  ./data/gnn_datasets/aging_coronal_expression_100per_2hop_2C0aug_200delaunay_expressionFeat_all_NoneInject/train\n",
      "Finished processing train dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 775/775 [01:30<00:00,  8.57it/s]\n",
      "100%|██████████| 190/190 [00:22<00:00,  8.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 387234\n",
      "Test samples: 94792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expression model initialized on cuda\n",
      "Starting Baseline training for 50 epochs...\n",
      " Epoch: 001, Train WL1: 6.7997, Test WL1: 6.7990, Test Spearman: 0.5687\n",
      " Epoch: 002, Train WL1: 6.4684, Test WL1: 6.4551, Test Spearman: 0.5806\n",
      " Epoch: 003, Train WL1: 6.3286, Test WL1: 6.3037, Test Spearman: 0.5857\n",
      " Epoch: 004, Train WL1: 6.2463, Test WL1: 6.2213, Test Spearman: 0.5876\n",
      " Epoch: 005, Train WL1: 6.1936, Test WL1: 6.1705, Test Spearman: 0.5883\n",
      " Epoch: 006, Train WL1: 6.1517, Test WL1: 6.1303, Test Spearman: 0.5898\n",
      " Epoch: 007, Train WL1: 6.1238, Test WL1: 6.1033, Test Spearman: 0.5907\n",
      " Epoch: 008, Train WL1: 6.1026, Test WL1: 6.0834, Test Spearman: 0.5916\n",
      " Epoch: 009, Train WL1: 6.0882, Test WL1: 6.0707, Test Spearman: 0.5913\n",
      " Epoch: 010, Train WL1: 6.0823, Test WL1: 6.0658, Test Spearman: 0.5921\n",
      " Epoch: 011, Train WL1: 6.0733, Test WL1: 6.0568, Test Spearman: 0.5925\n",
      " Epoch: 012, Train WL1: 6.0659, Test WL1: 6.0502, Test Spearman: 0.5923\n",
      " Epoch: 013, Train WL1: 6.0589, Test WL1: 6.0425, Test Spearman: 0.5917\n",
      " Epoch: 014, Train WL1: 6.0526, Test WL1: 6.0369, Test Spearman: 0.5931\n",
      " Epoch: 015, Train WL1: 6.0500, Test WL1: 6.0364, Test Spearman: 0.5927\n",
      " Epoch: 016, Train WL1: 6.0436, Test WL1: 6.0294, Test Spearman: 0.5932\n",
      " Epoch: 017, Train WL1: 6.0390, Test WL1: 6.0259, Test Spearman: 0.5936\n",
      " Epoch: 018, Train WL1: 6.0352, Test WL1: 6.0225, Test Spearman: 0.5941\n",
      " Epoch: 019, Train WL1: 6.0331, Test WL1: 6.0222, Test Spearman: 0.5936\n",
      " Epoch: 020, Train WL1: 6.0294, Test WL1: 6.0192, Test Spearman: 0.5928\n",
      " Epoch: 021, Train WL1: 6.0255, Test WL1: 6.0168, Test Spearman: 0.5941\n",
      " Epoch: 022, Train WL1: 6.0239, Test WL1: 6.0164, Test Spearman: 0.5929\n",
      " Epoch: 023, Train WL1: 6.0190, Test WL1: 6.0121, Test Spearman: 0.5940\n",
      " Epoch: 024, Train WL1: 6.0179, Test WL1: 6.0123, Test Spearman: 0.5943\n",
      " Epoch: 025, Train WL1: 6.0135, Test WL1: 6.0076, Test Spearman: 0.5938\n",
      " Epoch: 026, Train WL1: 6.0113, Test WL1: 6.0075, Test Spearman: 0.5939\n",
      " Epoch: 027, Train WL1: 6.0093, Test WL1: 6.0058, Test Spearman: 0.5941\n",
      " Epoch: 028, Train WL1: 6.0086, Test WL1: 6.0059, Test Spearman: 0.5942\n",
      " Epoch: 029, Train WL1: 6.0054, Test WL1: 6.0044, Test Spearman: 0.5936\n",
      " Epoch: 030, Train WL1: 6.0035, Test WL1: 6.0038, Test Spearman: 0.5940\n",
      " Epoch: 031, Train WL1: 6.0016, Test WL1: 6.0007, Test Spearman: 0.5940\n",
      " Epoch: 032, Train WL1: 6.0009, Test WL1: 6.0005, Test Spearman: 0.5945\n",
      " Epoch: 033, Train WL1: 6.0004, Test WL1: 6.0009, Test Spearman: 0.5948\n",
      " Epoch: 034, Train WL1: 5.9990, Test WL1: 6.0001, Test Spearman: 0.5949\n",
      " Epoch: 035, Train WL1: 5.9945, Test WL1: 5.9974, Test Spearman: 0.5946\n",
      " Epoch: 036, Train WL1: 5.9946, Test WL1: 5.9966, Test Spearman: 0.5941\n",
      " Epoch: 037, Train WL1: 5.9925, Test WL1: 5.9956, Test Spearman: 0.5948\n",
      " Epoch: 038, Train WL1: 5.9891, Test WL1: 5.9934, Test Spearman: 0.5950\n",
      " Epoch: 039, Train WL1: 5.9893, Test WL1: 5.9947, Test Spearman: 0.5948\n",
      " Epoch: 040, Train WL1: 5.9889, Test WL1: 5.9931, Test Spearman: 0.5942\n",
      " Epoch: 041, Train WL1: 5.9882, Test WL1: 5.9950, Test Spearman: 0.5950\n",
      " Epoch: 042, Train WL1: 5.9850, Test WL1: 5.9908, Test Spearman: 0.5951\n",
      " Epoch: 043, Train WL1: 5.9861, Test WL1: 5.9930, Test Spearman: 0.5949\n",
      " Epoch: 044, Train WL1: 5.9841, Test WL1: 5.9932, Test Spearman: 0.5949\n",
      " Epoch: 045, Train WL1: 5.9818, Test WL1: 5.9914, Test Spearman: 0.5946\n",
      " Epoch: 046, Train WL1: 5.9796, Test WL1: 5.9883, Test Spearman: 0.5952\n",
      " Epoch: 047, Train WL1: 5.9840, Test WL1: 5.9936, Test Spearman: 0.5950\n",
      " Epoch: 048, Train WL1: 5.9783, Test WL1: 5.9887, Test Spearman: 0.5953\n",
      " Epoch: 049, Train WL1: 5.9796, Test WL1: 5.9923, Test Spearman: 0.5951\n",
      " Epoch: 050, Train WL1: 5.9780, Test WL1: 5.9902, Test Spearman: 0.5958\n",
      "Baseline training completed. Model saved to output/api_demo/aging_coronal_expression_2hop_2augment_expression_none/weightedl1_1en04/model.pth\n",
      "Configuration saved to output/api_demo/aging_coronal_expression_2hop_2augment_expression_none/weightedl1_1en04/config.json\n",
      "Baseline training logs saved\n",
      "Plotting training and validation loss curves...\n"
     ]
    },
    {
     "ename": "NotADirectoryError",
     "evalue": "[Errno 20] Not a directory: 'output/api_demo/aging_coronal_expression_2hop_2augment_expression_none/weightedl1_1en04/model.pth/training.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_loader, gene_names, (model, model_config, trained_model_path) \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_perturbation_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtraining_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/oak/stanford/groups/akundaje/abuen/spatial/spatial-gnn/src/spatial_gnn/api/perturbation_api.py:116\u001b[0m, in \u001b[0;36mtrain_perturbation_model\u001b[0;34m(k_hop, augment_hop, center_celltypes, node_feature, learning_rate, loss, epochs, num_cells_per_ct_id, inject_feature, dataset, base_path, exp_name, adata_path, gene_list, normalize_total, predict_celltype, pool, predict_residuals, do_eval, device, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m test_loader, gene_names, (model, model_config, trained_model_path) \u001b[38;5;241m=\u001b[39m train_model_from_scratch(\n\u001b[1;32m     94\u001b[0m     dataset\u001b[38;5;241m=\u001b[39mdataset,\n\u001b[1;32m     95\u001b[0m     base_path\u001b[38;5;241m=\u001b[39mbase_path,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    113\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice\n\u001b[1;32m    114\u001b[0m )\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_eval:\n\u001b[0;32m--> 116\u001b[0m     \u001b[43meval_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrained_model_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43minject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgene_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgene_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining completed. Model saved to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrained_model_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m test_loader, gene_names, (model, model_config, trained_model_path)\n",
      "File \u001b[0;32m/oak/stanford/groups/akundaje/abuen/spatial/spatial-gnn/src/spatial_gnn/scripts/model_performance.py:173\u001b[0m, in \u001b[0;36meval_model\u001b[0;34m(model, test_loader, save_dir, device, inject, gene_names)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21meval_model\u001b[39m(model, test_loader, save_dir, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m, inject\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, gene_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    169\u001b[0m \n\u001b[1;32m    170\u001b[0m     \u001b[38;5;66;03m### LOSS CURVES\u001b[39;00m\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlotting training and validation loss curves...\u001b[39m\u001b[38;5;124m\"\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 173\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[1;32m    174\u001b[0m         b \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(handle)\n\u001b[1;32m    176\u001b[0m     best_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmin(b[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: 'output/api_demo/aging_coronal_expression_2hop_2augment_expression_none/weightedl1_1en04/model.pth/training.pkl'"
     ]
    }
   ],
   "source": [
    "test_loader, gene_names, (model, model_config, trained_model_path) = train_perturbation_model(\n",
    "    **training_args,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6e42da",
   "metadata": {},
   "source": [
    "### Inference with perturbation model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb989662",
   "metadata": {},
   "source": [
    "Define set of perturbations in the form of a dictionary mapping `cell type` → `gene name` → `multiplier`. For instance, entry `'T cell': {'Igf2': 0.0},` indicates knockout of IGF2 in all T-cells in the input dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66993368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define perturbations\n",
    "perturbation_dict = {\n",
    "    'T cell': {'Igf2': 0.0},  \n",
    "    'NSC': {'Sox9': 2.0},         \n",
    "    'Pericyte': {'Ccl4': 0.5}    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fafc86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save perturbation mask to anndata\n",
    "test_adata = sc.read_h5ad(test_data_path)\n",
    "test_data_path_perturbed = create_perturbation_mask(test_adata, perturbation_dict, save_path=test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c7442e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Predicting perturbation effects ===\")\n",
    "adata_perturbed = predict_perturbation_effects(\n",
    "    adata_path=test_data_path_perturbed,\n",
    "    model_path=model_path,\n",
    "    exp_name=\"aging_sagittal\",\n",
    "    perturbation_dict=perturbation_dict,\n",
    "    perturbation_mask_key=\"perturbation_mask\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d729773",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path = \"/oak/stanford/groups/akundaje/abuen/spatial/spatial-gnn/data/perturbed/aging_coronal_perturbed_result.h5ad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9e44b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc \n",
    "\n",
    "adata_result = sc.read_h5ad(result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b23f9ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 1453144 × 300\n",
       "    obs: 'volume', 'center_x', 'center_y', 'min_x', 'min_y', 'max_x', 'max_y', 'transcript_count', 'num_detected_genes', 'barcodeCount', 'mouse_id', 'slide_id', 'cohort', 'age', 'batch', 'celltype', 'region', 'subregion'\n",
       "    uns: 'neighbors', 'pca', 'perturbation_info', 'umap'\n",
       "    obsm: 'X_pca', 'X_umap', 'perturbation_mask', 'spatial'\n",
       "    varm: 'PCs'\n",
       "    layers: 'perturbation_effects', 'predicted_perturbed'\n",
       "    obsp: 'connectivities', 'distances'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78ef79f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "effects = adata_result.layers['perturbation_effects']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576c1f07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spatial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
